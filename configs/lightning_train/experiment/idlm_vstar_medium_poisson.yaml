# @package _global_
defaults:
- override /model_type: idlm
- override /model: ddit_small_idlm
- override /datamodule: star_idlm
- override /dataset: vstar_medium_v2
- override /collation_strategy: default
- override /noise_schedule: poisson

model:
  final_layer_without_normalization: true
  period_for_time_embedding: 0.5 # separates time which is in [0,1] well

noise_schedule:
  _target_: pcdd.noise_schedule.idlm.PoissonNoiseSchedule
  # TODO: update c to 0.0 and sigma to 20.0 after testing
  c: 1.0
  sigma: 12.0

loss:
  use_constraint: false # if set to true it will suppress the ce loss on input context
  ce_weight: 1.0
  length_loss_weight: 1.0
  length_loss: diffusion
  use_diffusion_weight_for_ce: true
  use_diffusion_weight_for_length_loss: true
  use_incomplete_gamma_factor: true
  use_n_drops_for_ce: true
  send_t_to_model: true

lightning_module:
  _target_: pcdd.diffusion.idlm_v2.IDLMLightningModuleForStarGraphs
  write_per_sample_metrics: true

predictor:
  sampling_method: sample_top_k
  top: 1
  second_sampling_method: sample_top_k
  second_top: 1
  max_steps: 200
  send_t_to_model: ${loss.send_t_to_model}
  use_first_step_factor: true
  length_temperature: 1.0

compile: false

trainer:
  precision: 32
  val_check_interval: null
  check_val_every_n_epoch: 2
  max_steps: 50000
  max_epochs: null

generative_perplexity:
  evaluators: null

optimizer:
  lr: 0.0001

callbacks:
  checkpoint_every_n_steps:
    every_n_train_steps: 500
    keep_multiple: 100
  checkpoint_monitor:
    monitor: val/ce

lr_scheduler:
  name: constant_with_warmup
  num_warmup_steps: 500

tags:
  compile: ${compile}
  precision: ${trainer.precision}


