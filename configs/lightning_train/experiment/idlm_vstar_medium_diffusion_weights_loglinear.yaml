# @package _global_
defaults:
- override /model_type: idlm
- override /model: ddit_small_idlm
- override /datamodule: star_idlm
- override /dataset: vstar_medium_v2
- override /collation_strategy: default
- override /noise_schedule: idlm_loglinear

model:
  final_layer_without_normalization: true
  period_for_time_embedding: 0.5 # separates time which is in [0,1] well

noise_schedule:
  _target_: pcdd.noise_schedule.idlm.LogLinearNoiseSchedule
  sigma_max: 50
  sigma_min: 5
  eps: 1e-3

loss:
  _target_: pcdd.diffusion.idlm_v2.IDLMLossWithMaskedCE
  use_constraint: false
  use_diffusion_weight_for_ce: true
  use_diffusion_weight_for_length_loss: true
  use_incomplete_gamma_factor: true
  length_loss: diffusion
  length_loss_weight: 1.0
  ce_weight: 1.0
  use_n_drops_for_ce: true
  send_t_to_model: true

lightning_module:
  _target_: pcdd.diffusion.idlm_v2.IDLMLightningModuleForStarGraphs
  write_per_sample_metrics: true

predictor:
  sampling_method: sample_top_k
  top: 1
  second_sampling_method: sample_top_k
  second_top: 1
  max_steps: 200
  length_temperature: 1.0
  use_first_step_factor: true
  send_t_to_model: ${loss.send_t_to_model}

compile: false

trainer:
  precision: bf16-mixed
  val_check_interval: null
  check_val_every_n_epoch: 2
  max_steps: 50000
  max_epochs: null

generative_perplexity:
  evaluators: null

optimizer:
  lr: 0.0001

callbacks:
  checkpoint_every_n_steps:
    every_n_train_steps: 500
    keep_multiple: 100
  checkpoint_monitor:
    monitor: val/ce

lr_scheduler:
  name: constant_with_warmup
  num_warmup_steps: 500

tags:
  compile: ${compile}
  precision: ${trainer.precision}
  factor: hyp1f1


